{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDUBlXwohzin",
        "outputId": "966cf345-0f72-4f5c-ccff-9046e4b381bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Captions:\n",
            "DKTE‚Äôs Textile Students Selected by Reed & Tailor Company\n",
            "The news of DKTE‚Äôs Textile students being successfully placed at Reed & Tailor Company has been widely published by various leading newspapers.\n",
            "...........................................................................................\n",
            "DKTE Society's\n",
            "TEXTILE AND ENGINEERING INSTITUTE, ICHALKARANJI\n",
            "AN EMPOWERED AUTONOMOUS INSTITUTE\n",
            "NAAC ACCREDITED WITH 'A+' GRADE\n",
            "...........................................................................................\n",
            "#DKTE #CampusPlacement #SuccessStory #TextileIndustry\n",
            "A one-week FDP on Testing of Technical Textiles was organized from 2nd to 7th December 2024 by Department of Textiles and AICTE Idea lab in Collaboration with Institutions Innovation Council.\n",
            "The FDP included prominent speakers, including Ms. Seema Patel, Joint Director, Testing and Analysis, Wool Research Association, Mumbai. Ms. Seema's enlightening lesson focused on \"Evaluation of Protective Textiles, Geo Textiles, Industrial Workwear, etc.\" Prof. (Dr.) S. B. Vhanbatte, Prof. P. S. Joshi, and Prof. S. K. Laga from D.K.T.E's Textile and Engineering Institute gave a presentation titled \"Overview of Technical Textiles, Testing of Nonwovens, Standard and Certification for Technical Textile Testing, Microscopic Techniques for Structural Analysis, etc.\"\n",
            "A major accomplishment of this FDP was the effective involvement of 25 faculty members, demonstrating their dedication to improving their design thinking skills in technical textile testing.\n",
            "The program organisers, Prof. (Dr.) S. D. Asagekar, Dr. P. M. Katkar, and Mr. Mandar S. Kulkarni, worked tirelessly to ensure the FDP's success. Prof. (Dr.) U. J. Patil, Dy. Director and Head of Textile Department, and our Institute's Director, Prof. (Dr.) L. S. Admuthe, provided the essential assistance to ensure the event's success.\n",
            "...........................................................................................\n",
            "DKTE Society's\n",
            "TEXTILE AND ENGINEERING INSTITUTE, ICHALKARANJI\n",
            "AN EMPOWERED AUTONOMOUS INSTITUTE\n",
            "NAAC ACCREDITED WITH 'A+' GRADE\n",
            "...........................................................................................\n",
            "#DKTE \n",
            "# Textile Department\n",
            "# One-week Faculty Development Program\n",
            "# Testing of Technical Textiles\n",
            "Congratulation to Prof. Dr. R. N. Narkhedkar, tops NPTEL Course on ‚ÄúYarn Manufacture I: Principle of Carding & Drawing‚Äù.\n",
            "...........................................................................................\n",
            "DKTE Society's\n",
            "TEXTILE AND ENGINEERING INSTITUTE, ICHALKARANJI\n",
            "AN EMPOWERED AUTONOMOUS INSTITUTE‚Ä¶ See more\n",
            "The Electrical Engineering Department of DKTE's Textile and Engineering Institute has signed an MoU with Tata Power Skill Development Institute (TPSDI) to provide students with hands-on training and industry insights. This collaboration aims to bridge the gap between academic learning and industry requirements, offering students valuable internship opportunities. The signing ceremony was attended by Sandeep Kulkarni, Director of TPSDI, Vinayak Kulkarni, and Prof. Pravin Magdum.This ceremony was held on 3 january 2025 .\n",
            "...........................................................................................\n",
            "DKTE Society's\n",
            "TEXTILE AND ENGINEERING INSTITUTE, ICHALKARANJI\n",
            "AN EMPOWERED AUTONOMOUS INSTITUTE\n",
            "NAAC ACCREDITED WITH 'A+' GRADE\n",
            "...........................................................................................\n",
            "#SkillDevelopment #IndustryCollaboration #Education #MoU #Internships #dkte #TataPower #internship #electricalengineering\n",
            "DKTE's Team Innovators secured third place in the national-level design competition in Chennai, a success widely covered by multiple newspapers.The cpmpetiton held on 22 nd december .the participants wew ABC AND DAB.\n",
            "...........................................................................................\n",
            "DKTE Society's\n",
            "TEXTILE AND ENGINEERING INSTITUTE, ICHALKARANJI\n",
            "AN EMPOWERED AUTONOMOUS INSTITUTE\n",
            "NAAC ACCREDITED WITH 'A+' GRADE\n",
            "...........................................................................................\n",
            "#DKTE \n",
            "# Team Innovators \n",
            "# News Release\n",
            "The Civil Engineering Department in collaboration with the Institution's Innovation Council (IIC) successfully organized an insightful session on:\n",
            "üåü \"Empowering Innovation and Entrepreneurship Skills through PRIMAVERA Software in Construction Project Management\" Led by Er. Kushal Kumar Dongare, Civil & Land Revenue Work Consultant, Jaysingpur, the session provided students with foundational knowledge and practical insights into PRIMAVERA software, including:\n",
            "‚úîÔ∏è Basics of project planning and scheduling in construction\n",
            "‚úîÔ∏è Efficient resource and time management techniques\n",
            "‚úîÔ∏è Understanding the role of PRIMAVERA in large-scale project execution\n",
            "This engaging session empowered students with essential tools and skills for innovation and entrepreneurship in construction project management held on 21 december 2024 and \n",
            "...........................................................................................\n",
            "DKTE Society's\n",
            "TEXTILE AND ENGINEERING INSTITUTE, ICHALKARANJI\n",
            "AN EMPOWERED AUTONOMOUS INSTITUTE\n",
            "NAAC ACCREDITED WITH 'A+' GRADE\n",
            "...........................................................................................\n",
            "#DKTE Civil Engineering Department \n",
            "#Skill Development \n",
            "#Innovation & Entrepreneurship\n",
            "'Dhoot Transmission Pvt. Ltd. (DTPL)', one of the leading Indian manufacturers of wiring harnesses and power cords, has given placement offers to our 27 girl students.\n",
            "The names of the selected students are as follows:\n",
            "Snehal Powar, Sumitra Hulle, Pooja Bhasme, Ashwini Ghatte, Shweta Ugare, Gouri Patil, Sonali Dingane, Supriya Dubule, Priyanka Chougule, Yogita Chogule, Vidya Pawar, Shubhangi Koli.\n",
            "Shweta Patankar, Shivani Desai, Samarthi Bambare, Aarati Bange, Dhanashri Patil, Snehal Patil, Tejeshri Shirse, Shivani Kumbhar, Pooja Magdum, Swapnali Vandure, Pooja Shinde, Neha Killedar, Tejaswini Patil, Komal Patil, Gajala Mulla, Prajyot Koli\n",
            "Congratulations!!!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "page_id = \"475799095608711\"\n",
        "access_token = \"EAA2rrMSfqJsBPEwYZCCDJCK7G6cZAinU4ZA1nXOYyKm6Ly36OckMLbawch3TwtTGzapMfZACM4Qac2sH3soIuDT8hHpeLyiI4ittv3G1E0ZB4DBWORxR2EIgiESf3U2Icpujo1yf0FXW7TRmZBy1DG6fU5iQZCQtUDZBotrjbZBQJbEec09UY9wBYIpllnPYg6WfJUVZAD8gqjChsM9WxCbyqtFHDLNlXwpkxPjWkQTy0n\"\n",
        "url = f\"https://graph.facebook.com/{page_id}/posts?fields=message&access_token={access_token}\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    response_json = response.json()\n",
        "    captions = [post[\"message\"] for post in response_json.get(\"data\", []) if \"message\" in post]\n",
        "    print(\"Extracted Captions:\")\n",
        "    for caption in captions:\n",
        "        print(caption)\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}, {response.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2YYWE0yp2Yt"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_GMe9gBh8Ss",
        "outputId": "4aed47d6-49c5-418a-9fe7-f16d511267d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captions saved to captions.csv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "# Save captions to a CSV file\n",
        "with open(\"captions.csv\", \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Caption\"])  # Write header\n",
        "    for caption in captions:\n",
        "        writer.writerow([caption])\n",
        "\n",
        "print(\"Captions saved to captions.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GTM0uOJYh8PM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "stmVD38Fh8M1"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load the training dataset\n",
        "train_file_path = '/content/training_data_set.xlsx'\n",
        "train_data = pd.read_excel(train_file_path)\n",
        "# Rename columns for clarity\n",
        "train_data.columns = ['SerialNo', 'Post', 'Label']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "55bFviIkh8Kq"
      },
      "outputs": [],
      "source": [
        "# Step 2: Preprocess the training data\n",
        "train_data.dropna(subset=['Post', 'Label'], inplace=True)\n",
        "X_train = train_data['Post']\n",
        "y_train = train_data['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3_OdhMfVh8IT"
      },
      "outputs": [],
      "source": [
        "# Step 3: Convert text to numerical features using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "571CxqmQh8Fr",
        "outputId": "5d8ee3ef-2dc3-4847-90d4-87c2da7e273b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train a classification model\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Save the trained model and vectorizer\n",
        "joblib.dump(model, 'post_classification_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
        "print(\"Model trained and saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "R12twWgsh8DL"
      },
      "outputs": [],
      "source": [
        "# Step 5: Load the captions dataset for prediction\n",
        "captions_file_path = '/content/captions.csv'\n",
        "captions_data = pd.read_csv(captions_file_path)\n",
        "\n",
        "# Ensure the column name is consistent\n",
        "captions_data.columns = ['Post']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Dld1cb2Yh8Am"
      },
      "outputs": [],
      "source": [
        "# Step 6: Preprocess the captions data\n",
        "captions_data.dropna(subset=['Post'], inplace=True)\n",
        "X_captions = captions_data['Post']\n",
        "\n",
        "# Transform the captions using the saved vectorizer\n",
        "X_captions_tfidf = vectorizer.transform(X_captions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "epryR7R5h7-P"
      },
      "outputs": [],
      "source": [
        "# Step 7: Predict the classes\n",
        "predicted_labels = model.predict(X_captions_tfidf)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# X = raw captions\n",
        "X = train_data['Post']   # list of text captions\n",
        "y = train_data['Label']  # list of their actual class labels\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize\n",
        "X_train_tfidf = vectorizer.transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Predict on test set\n",
        "predicted_labels = model.predict(X_test_tfidf)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, predicted_labels)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6n3y8-n6tZq",
        "outputId": "b12394f4-0cbe-487f-cfce-d67bb5806a8d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 96.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0Mklfr64iUsg"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOeU9NSeiUpD",
        "outputId": "78451f60-c06d-4bd4-b30d-3e5c1ae5d20b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to /mnt/data/captions_with_predictions.csv.\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Save the predictions to a new file\n",
        "captions_data['Predicted_Label'] = predicted_labels\n",
        "output_file_path = '/mnt/data/captions_with_predictions.csv'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "\n",
        "captions_data.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_file_path}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYJrNKxqiUnM",
        "outputId": "fd7e70c5-89e3-4db7-adff-912f19bd9b4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHIQht5vih3i",
        "outputId": "85bc4fb1-2907-4f75-ee32-6bfec5f3cb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structured data with classification has been saved to /mnt/data/structured_captions_with_classification.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# Load the English NLP model from spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a function to extract structured information\n",
        "def extract_information_with_participant_names(caption):\n",
        "    # Process the caption using spaCy\n",
        "    doc = nlp(caption)\n",
        "\n",
        "    # Extract a heading\n",
        "    heading = caption.split(\":\")[0] if \":\" in caption else caption[:50]\n",
        "\n",
        "    # Regex patterns for date, duration, and department\n",
        "    date_pattern = r\"\\b(?:\\d{1,2}(?:st|nd|rd|th)?\\s+\\w+\\s+\\d{4}|\\w+\\s+\\d{1,2},?\\s+\\d{4})\\b\"\n",
        "    duration_pattern = r\"\\b(?:\\d+\\s+(?:hour|day|week|month|year)s?)\\b\"\n",
        "    department_pattern = r\"\\b(?:Department of \\w+|Electrical Engineering|Mechanical Engineering|Computer Science)\\b\"\n",
        "\n",
        "    # Extract entities using regex\n",
        "    date = re.search(date_pattern, caption)\n",
        "    duration = re.search(duration_pattern, caption)\n",
        "    department = re.search(department_pattern, caption, re.IGNORECASE)\n",
        "\n",
        "    # Extract participant names using spaCy\n",
        "    participants = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
        "\n",
        "    # Return structured information\n",
        "    return {\n",
        "        \"Heading\": heading.strip(),\n",
        "        \"Date\": date.group(0) if date else None,\n",
        "        \"Duration\": duration.group(0) if duration else None,\n",
        "        \"Department\": department.group(0) if department else None,\n",
        "        \"Participants\": \", \".join(participants) if participants else None,\n",
        "    }\n",
        "\n",
        "# Step 1: Load the captions dataset with predictions\n",
        "captions_file_path = '/mnt/data/captions_with_predictions.csv'\n",
        "captions_data = pd.read_csv(captions_file_path)\n",
        "\n",
        "# Ensure the column names are consistent\n",
        "captions_data.columns = ['Post', 'Predicted_Label']\n",
        "\n",
        "# Step 2: Apply the NLP extraction function\n",
        "structured_data = captions_data['Post'].apply(extract_information_with_participant_names)\n",
        "structured_df = pd.DataFrame(list(structured_data))\n",
        "\n",
        "# Combine the structured information with the original data\n",
        "result_df = pd.concat([captions_data, structured_df], axis=1)\n",
        "\n",
        "# Step 3: Save the combined structured data to a single file\n",
        "output_file_path = '/mnt/data/structured_captions_with_classification.csv'\n",
        "result_df.to_csv(output_file_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"Structured data with classification has been saved to {output_file_path}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOnGopTmih1G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ru4vXi3Qihyd",
        "outputId": "01a0af06-7d6f-44f2-96b9-abb689101acc"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_bcb49d14-e6f1-4420-9862-6cb9aeff9ea8\", \"post_classification_model.pkl\", 2561233)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_65a54d61-5ccf-44ba-8cdd-42f77bead42a\", \"tfidf_vectorizer.pkl\", 128592)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpEA1Ev-ihwa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4cbRON-ihuA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}